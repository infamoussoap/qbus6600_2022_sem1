{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore vs Exploit\n",
    "\n",
    "When it comes to reinforcement leanrning and searching algorithms, there are two things we need to keep in mind - to explore or to exploit. [AI ML Analytics](https://ai-ml-analytics.com/reinforcement-learning-exploration-vs-exploitation-tradeoff/#:~:text=Exploration%20is%20more%20of%20a,lead%20to%20long%20term%20benefit.&text=Exploitation%20basically%20exploits%20the%20agent's,to%20get%20the%20most%20reward.)\n",
    "\n",
    "    Exploration is more of a long-term benefit concept where it allows the agent to improve its knowledge about each action which could lead to long term benefit.\n",
    "\n",
    "    Exploitation basically exploits the agentâ€™s current estimated value and chooses the greedy approach to get the most reward. However, the agent is being greedy with the estimated value and not the actual value, so chances are it might not get the most reward.\n",
    "\n",
    "Really there are two modes we want to be in when we perform our search, either in exploration or exploitation model. We can either explore the search space where we can hopefully find a better solution, or we can use the information we already know and greedily find the best solution. \n",
    "\n",
    "The methods that exemplify both are Randomized Search (pure exploration) and Coordinate descent (pure exploitation). In randomized search all we ever do is explore the search space, but we never use the information we found to improve our future results. In coordinate descent we only exploit, because we simply start at what ever position we are in and greedy find the optimal parameter by only optimizing one parameter at a time.\n",
    "\n",
    "We have seen coordinate descent fail in this fashion before. Because of the degenerate starting point, coordinate descent only exploits and fails to find the true optimum result. But if we could make coordinate descent explore a bit more we can perhaps get better results. A simple way of doing this is to just repeat coordinate descent multiple times at different starting positions.\n",
    "\n",
    "But what if an algorithm can do both exploring and exploiting by itself? Enter genetic algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms\n",
    "\n",
    "The broad idea of genetic algorithms (GA) follows the ideas of evolution, or more specifically the survival of the fittest. There are 3 main points with GA\n",
    "\n",
    "1. Start with a population of people, called a generation\n",
    "2. Rank everyone in this generation by their fitness\n",
    "3. Take the most fittess people and use their \"DNA\" to make children for the next population\n",
    "4. Repeat\n",
    "\n",
    "### Why Does this Optimize\n",
    "The first questions to ask is, does this even give us an optimum solution? The answer is yes. The idea is that since only the \"fittess\" people in the population are used to make the next population, only the fittess \"DNA\" will be carried over to the next generation. This results in a generation that is more \"fit\" than the previous generation. Repeating this over and over again, and you will eventually have a very fit population, that is a set of solutions that is near optimal.\n",
    "\n",
    "This is known as genetic drift, where the genes of the population will eventually drift towards the optimal solutions.\n",
    "\n",
    "### Introducing Exploring\n",
    "\n",
    "Now, genetic drift can be a good thing, but if the initial starting position was bad it is likely that the population will eventually drift towards a suboptimal point. Meaning that it is only exploiting. \n",
    "\n",
    "To fix this we introduce exploration by mutation of the children. As is true with the typical DNA, we consider the \"DNA\" of a solution to be comprised of \"chromosomes\". When a child is being made these chromosomes can be mutated with a probability $p$. This helps prevent genetic drift by suggesting a random that may or may not be better. If it is better, this DNA will be used as a parent to make the next generation and therefore preventing the genetic drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

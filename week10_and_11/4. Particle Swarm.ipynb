{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E4Dd3p1b4gdj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "epbM1MdvVRAa"
   },
   "outputs": [],
   "source": [
    "perth = pd.read_csv('perth_clean.csv')\n",
    "perth = pd.get_dummies(perth, columns=['suburb'])\n",
    "\n",
    "train_indices, test_indices = train_test_split(perth.index, test_size=0.2, random_state=0)\n",
    "\n",
    "perth_train = perth.loc[train_indices].copy()\n",
    "perth_test = perth.loc[test_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZLvNU8JVaLi",
    "outputId": "dcade13a-8727-45ba-c29b-f8dfc6b76fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled set length 5384\n"
     ]
    }
   ],
   "source": [
    "indices = list(perth_train.index.copy())\n",
    "# np.random.seed(5)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "sampled_indices = indices[:int(len(indices) * 0.2)]\n",
    "sampled_perth = perth_train.loc[sampled_indices, :].copy()\n",
    "\n",
    "print(\"Sampled set length\", len(sampled_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xzjWwAm6VbLW"
   },
   "outputs": [],
   "source": [
    "n = len(sampled_perth)\n",
    "sampled_train_indices, sampled_valid_indices = train_test_split(np.arange(n), test_size=0.2, random_state=0)\n",
    "\n",
    "sampled_x_train = sampled_perth.iloc[sampled_train_indices].drop('log10_price', axis=1)\n",
    "sampled_y_train = sampled_perth.iloc[sampled_train_indices]['log10_price'].copy()\n",
    "\n",
    "sampled_x_valid = sampled_perth.iloc[sampled_valid_indices].drop('log10_price', axis=1)\n",
    "sampled_y_valid = sampled_perth.iloc[sampled_valid_indices]['log10_price'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3owfqprmVcLz"
   },
   "outputs": [],
   "source": [
    "train_data = (sampled_x_train, sampled_y_train)\n",
    "valid_data = (sampled_x_valid, sampled_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_qallwQVdhu",
    "outputId": "43d4735c-4b5b-424a-dffa-95de09fda576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training length of sampled data 4307\n",
      "Validiation length of sampled data 1077\n"
     ]
    }
   ],
   "source": [
    "print(\"Training length of sampled data\", len(sampled_x_train))\n",
    "print(\"Validiation length of sampled data\", len(sampled_x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxM13JAikQjD"
   },
   "source": [
    "$$X^i(t+1) = X^i(t) + V^i(t+1)$$\n",
    "\n",
    "$$V^i(t+1)=wV^i(t) + c_1r_1(p^i-X^i(t))+c_2r_2(g^i-X^i(t))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pcOtB6RHvER9"
   },
   "outputs": [],
   "source": [
    "class SwarmOptimizer:\n",
    "    def __init__(self, n_particles, w=0.8, c1=0.1, c2=0.1):\n",
    "        self.n_particles = n_particles\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "        self.swarm = self._generate_swarm(n_particles)\n",
    "        self.swarm_velocities = self._generate_swarm_velocities(n_particles)\n",
    "\n",
    "        self.current_best_particle = None\n",
    "        self.current_best_score = None\n",
    "\n",
    "        self.global_best_particle = None\n",
    "        self.global_best_score = None\n",
    "\n",
    "    def update_swarm(self, train_data, valid_data, n_tries=1):\n",
    "        for i in range(n_tries):\n",
    "            print(f\"Updating swarm - {i + 1} of {n_tries} updates\")\n",
    "            self._update_swarm(train_data, valid_data)\n",
    "\n",
    "    def _update_swarm(self, train_data, valid_data):\n",
    "        self.update_current_best_particle(train_data, valid_data)\n",
    "        self.update_global_best_particle()\n",
    "\n",
    "        self.update_particle_velocities()\n",
    "        self.update_particles()\n",
    "\n",
    "    def update_current_best_particle(self, train_data, valid_data):\n",
    "        best_particle_index, best_particle_score = self.best_particle_of_swarm(train_data, valid_data)\n",
    "\n",
    "        self.current_best_particle = self.swarm[best_particle_index].copy()\n",
    "        self.current_best_score = best_particle_score\n",
    "\n",
    "    def update_global_best_particle(self):\n",
    "        if self.global_best_particle is None:\n",
    "            self.global_best_particle = self.current_best_particle.copy()\n",
    "            self.global_best_score = self.current_best_score\n",
    "\n",
    "        elif self.current_best_score < self.global_best_score:\n",
    "            self.global_best_particle = self.current_best_particle.copy()\n",
    "            self.global_best_score = self.current_best_score\n",
    "\n",
    "    def update_particle_velocities(self):\n",
    "        w = self.w\n",
    "        c1, c2 = self.c1, self.c2\n",
    "\n",
    "        r1, r2 = np.random.rand(2)\n",
    "        for particle, velocity in zip(self.swarm, self.swarm_velocities):\n",
    "            for key in velocity.keys():\n",
    "                p = self.current_best_particle[key]\n",
    "                g = self.global_best_particle[key]\n",
    "                X = particle[key]\n",
    "\n",
    "                velocity[key] = w * velocity[key] + c1 * r1 * (p - X) + c2 * r2 * (g - X)\n",
    "\n",
    "    def update_particles(self):\n",
    "        \"\"\" Note that since the `learning_rate` and the `subsample` must be\n",
    "            between 0 and 1, we must clip it ever time to make sure this is correct\n",
    "            If you want to solve a different problem, then you may need to change this\n",
    "        \"\"\"\n",
    "        for particle, velocity in zip(self.swarm, self.swarm_velocities):\n",
    "            for key in velocity.keys():\n",
    "                particle[key] = np.clip(particle[key] + velocity[key], 1e-5, 1)\n",
    "    \n",
    "\n",
    "    def best_particle_of_swarm(self, train_data, valid_data):\n",
    "        swarm_scores = self.score_swarm(train_data, valid_data)\n",
    "\n",
    "        best_index = np.argmin(swarm_scores)\n",
    "        return best_index, swarm_scores[best_index]\n",
    "\n",
    "    def score_swarm(self, train_data, valid_data):\n",
    "        swarm_scores = []\n",
    "        for i, particle in enumerate(self.swarm):\n",
    "            base_model = XGBRegressor(objective='reg:squarederror', random_state=0, \n",
    "                                        n_estimators=200, max_depth=10, **particle)\n",
    "            \n",
    "            score = self._score_model(base_model, train_data, valid_data)\n",
    "            swarm_scores.append(score)\n",
    "            \n",
    "            print(f\"{i + 1} of {self.n_particles}: Particle {particle} has score {score}\")\n",
    "\n",
    "        return swarm_scores\n",
    "\n",
    "    @staticmethod\n",
    "    def _score_model(model, train_data, valid_data):\n",
    "        x_train, y_train = train_data\n",
    "        x_valid, y_valid = valid_data\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(x_valid)\n",
    "        return np.sqrt(np.mean((y_valid - y_pred) ** 2))\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_swarm(n_particles):\n",
    "        swarm = []\n",
    "        for i in range(n_particles):\n",
    "            new_particle = {}\n",
    "            new_particle['learning_rate'] = np.random.uniform(low=0, high=1)\n",
    "            new_particle['subsample'] = np.random.uniform(low=0, high=1)\n",
    "\n",
    "            swarm.append(new_particle)\n",
    "\n",
    "        return swarm\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_swarm_velocities(n_particles):\n",
    "        return [{'learning_rate': 0, 'subsample': 0} for _ in range(n_particles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "avSEEih50hsA"
   },
   "outputs": [],
   "source": [
    "swarm_optimizer = SwarmOptimizer(n_particles=10, w=0.8, c1=0.1, c2=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXjMgwa_0sd3",
    "outputId": "360f9b6e-eb01-43d5-8295-91bcb8e12722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating swarm - 1 of 1 updates\n",
      "1 of 10: Particle {'learning_rate': 0.8886824408606375, 'subsample': 0.37354936513718706} has score 0.2645394427216232\n",
      "2 of 10: Particle {'learning_rate': 0.2084004527721237, 'subsample': 0.5978973760511196} has score 0.0979382481304867\n",
      "3 of 10: Particle {'learning_rate': 0.8046436682852822, 'subsample': 0.5221258212643487} has score 0.14217137931937845\n",
      "4 of 10: Particle {'learning_rate': 0.7523920546179751, 'subsample': 0.3794787259605792} has score 0.184693217178702\n",
      "5 of 10: Particle {'learning_rate': 0.6101118551991185, 'subsample': 0.01602030104858443} has score 3863.017043048879\n",
      "6 of 10: Particle {'learning_rate': 0.7095152325409344, 'subsample': 0.5519059682912614} has score 0.12756089127203957\n",
      "7 of 10: Particle {'learning_rate': 0.9403559371597094, 'subsample': 0.7824331006411478} has score 0.12882397601050208\n",
      "8 of 10: Particle {'learning_rate': 0.6107775097171121, 'subsample': 0.44806591933498363} has score 0.13539127988439503\n",
      "9 of 10: Particle {'learning_rate': 0.7114173381820876, 'subsample': 0.6412113756364315} has score 0.12550789288064484\n",
      "10 of 10: Particle {'learning_rate': 0.02357771613946269, 'subsample': 0.4397798202066072} has score 0.10775646574283067\n"
     ]
    }
   ],
   "source": [
    "swarm_optimizer.update_swarm(train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qCDNXvX1aQA",
    "outputId": "1e5df0f4-ec77-46cc-a16c-7dfdc7455833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best particle {'learning_rate': 0.2084004527721237, 'subsample': 0.5978973760511196} with score 0.0979382481304867\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best particle {swarm_optimizer.global_best_particle} with score {swarm_optimizer.global_best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fx3wiWd91aXz",
    "outputId": "a011d72a-4080-40bc-fdce-f11894a5f589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating swarm - 1 of 1 updates\n",
      "1 of 10: Particle {'learning_rate': 0.8169481265673152, 'subsample': 0.3972063941454103} has score 0.2023247108633759\n",
      "2 of 10: Particle {'learning_rate': 0.2084004527721237, 'subsample': 0.5978973760511196} has score 0.0979382481304867\n",
      "3 of 10: Particle {'learning_rate': 0.7417710669731967, 'subsample': 0.5301157734029326} has score 0.13622889715140007\n",
      "4 of 10: Particle {'learning_rate': 0.6950292767949339, 'subsample': 0.40251051625851575} has score 0.15085627031197804\n",
      "5 of 10: Particle {'learning_rate': 0.5677522271309416, 'subsample': 0.07737802285979305} has score 37.253570669083885\n",
      "6 of 10: Particle {'learning_rate': 0.6566737260210121, 'subsample': 0.5567556661471581} has score 0.12772468879700685\n",
      "7 of 10: Particle {'learning_rate': 0.8631727606459307, 'subsample': 0.7629741940437785} has score 0.13045814642965103\n",
      "8 of 10: Particle {'learning_rate': 0.5683476897708015, 'subsample': 0.4638653333945885} has score 0.12708456400751378\n",
      "9 of 10: Particle {'learning_rate': 0.6583752585964798, 'subsample': 0.6366440048784844} has score 0.12467066497449684\n",
      "10 of 10: Particle {'learning_rate': 0.04306688755705752, 'subsample': 0.45645298610669627} has score 0.08970690579896985\n"
     ]
    }
   ],
   "source": [
    "swarm_optimizer.update_swarm(train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAIxtuWd3XCM",
    "outputId": "e0f5b610-64fd-42b6-c778-6410183b4585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best particle {'learning_rate': 0.04306688755705752, 'subsample': 0.45645298610669627} with score 0.08970690579896985\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best particle {swarm_optimizer.global_best_particle} with score {swarm_optimizer.global_best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6Fa6n1F3h_k",
    "outputId": "d00d7055-35f9-424c-b2ae-9571660bf379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating swarm - 1 of 3 updates\n",
      "1 of 10: Particle {'learning_rate': 0.688810605230655, 'subsample': 0.4215484821936451} has score 0.15507472609018771\n",
      "2 of 10: Particle {'learning_rate': 0.19328526363654866, 'subsample': 0.5849661923353694} has score 0.0965641572669653\n",
      "3 of 10: Particle {'learning_rate': 0.6275957822356149, 'subsample': 0.5297733072873151} has score 0.12746150169789633\n",
      "4 of 10: Particle {'learning_rate': 0.5895350968658785, 'subsample': 0.4258674978355289} has score 0.13293865479295106\n",
      "5 of 10: Particle {'learning_rate': 0.4858965386597291, 'subsample': 0.1611201381915775} has score 0.3149685246177858\n",
      "6 of 10: Particle {'learning_rate': 0.5583031191298593, 'subsample': 0.5514655140289605} has score 0.11585164436459759\n",
      "7 of 10: Particle {'learning_rate': 0.7264501831605468, 'subsample': 0.719384168358412} has score 0.12219088462865718\n",
      "8 of 10: Particle {'learning_rate': 0.4863814091813481, 'subsample': 0.4758272101620747} has score 0.11876840442325756\n",
      "9 of 10: Particle {'learning_rate': 0.559688635083661, 'subsample': 0.6165166152719326} has score 0.11815294206282688\n",
      "10 of 10: Particle {'learning_rate': 0.05865822469113339, 'subsample': 0.4697915188267675} has score 0.08898686276786343\n",
      "Updating swarm - 2 of 3 updates\n",
      "1 of 10: Particle {'learning_rate': 0.5065499416167247, 'subsample': 0.44712768120212004} has score 0.12532126193101284\n",
      "2 of 10: Particle {'learning_rate': 0.16415502165375084, 'subsample': 0.5600450016453207} has score 0.09533490271766358\n",
      "3 of 10: Particle {'learning_rate': 0.46425211613618095, 'subsample': 0.5219081761950621} has score 0.11432726987620903\n",
      "4 of 10: Particle {'learning_rate': 0.4379531880551598, 'subsample': 0.4501120069083782} has score 0.11269110868266574\n",
      "5 of 10: Particle {'learning_rate': 0.36634168231881103, 'subsample': 0.2671785756451373} has score 0.12149724453110983\n",
      "6 of 10: Particle {'learning_rate': 0.4163727165442415, 'subsample': 0.5368969179761228} has score 0.1060057800187044\n",
      "7 of 10: Particle {'learning_rate': 0.5325578955818762, 'subsample': 0.6529242719444647} has score 0.10707866475749542\n",
      "8 of 10: Particle {'learning_rate': 0.3666767150396565, 'subsample': 0.4846328482610948} has score 0.10367689589701687\n",
      "9 of 10: Particle {'learning_rate': 0.41733007146494694, 'subsample': 0.5818455103769432} has score 0.10610710698899914\n",
      "10 of 10: Particle {'learning_rate': 0.07113129439839408, 'subsample': 0.48046234500282453} has score 0.09083128619027017\n",
      "Updating swarm - 3 of 3 updates\n",
      "1 of 10: Particle {'learning_rate': 0.3427922370988681, 'subsample': 0.4686596464263829} has score 0.10568677965687294\n",
      "2 of 10: Particle {'learning_rate': 0.1367583530768213, 'subsample': 0.5366068989930697} has score 0.09451096108103826\n",
      "3 of 10: Particle {'learning_rate': 0.3173397996900843, 'subsample': 0.5136583158989125} has score 0.10460073715880173\n",
      "4 of 10: Particle {'learning_rate': 0.3015145932333553, 'subsample': 0.470455444730031} has score 0.10306545470093617\n",
      "5 of 10: Particle {'learning_rate': 0.25842284213750805, 'subsample': 0.36037645943223084} has score 0.10548738715584959\n",
      "6 of 10: Particle {'learning_rate': 0.2885286868860811, 'subsample': 0.5226776923723994} has score 0.10076204957409352\n",
      "7 of 10: Particle {'learning_rate': 0.3584423518011721, 'subsample': 0.5924963870933475} has score 0.10406384928796047\n",
      "8 of 10: Particle {'learning_rate': 0.2586244458667857, 'subsample': 0.4912281332511639} has score 0.10100050816405656\n",
      "9 of 10: Particle {'learning_rate': 0.28910476889314446, 'subsample': 0.5497252112861332} has score 0.10027583618539411\n",
      "10 of 10: Particle {'learning_rate': 0.08078193895624593, 'subsample': 0.488718560431798} has score 0.0904552028107499\n"
     ]
    }
   ],
   "source": [
    "swarm_optimizer.update_swarm(train_data, valid_data, n_tries=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4q9mteNM7h6a",
    "outputId": "0c4fdc7c-042d-41f0-8e08-c3768055c94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating swarm - 1 of 1 updates\n",
      "1 of 10: Particle {'learning_rate': 0.16559099972230232, 'subsample': 0.4879387656503457} has score 0.09594760104547065\n",
      "2 of 10: Particle {'learning_rate': 0.10372060796878124, 'subsample': 0.5083428033397314} has score 0.09062555417305108\n",
      "3 of 10: Particle {'learning_rate': 0.15794782840105054, 'subsample': 0.501451520224029} has score 0.09224949717546857\n",
      "4 of 10: Particle {'learning_rate': 0.15319564053784734, 'subsample': 0.4884780300780606} has score 0.09296904253674342\n",
      "5 of 10: Particle {'learning_rate': 0.1402555188957198, 'subsample': 0.45542215688258075} has score 0.09565136147617796\n",
      "6 of 10: Particle {'learning_rate': 0.14929607267407585, 'subsample': 0.5041599696542566} has score 0.09429065853538843\n",
      "7 of 10: Particle {'learning_rate': 0.1702906088774425, 'subsample': 0.5251259870382824} has score 0.09343593194080406\n",
      "8 of 10: Particle {'learning_rate': 0.14031605894605464, 'subsample': 0.49471590877785176} has score 0.09410553978966164\n",
      "9 of 10: Particle {'learning_rate': 0.1494690656729137, 'subsample': 0.5122821316913244} has score 0.09270067402620881\n",
      "10 of 10: Particle {'learning_rate': 0.08691132105446604, 'subsample': 0.4939623033492828} has score 0.08892643429148894\n"
     ]
    }
   ],
   "source": [
    "swarm_optimizer.update_swarm(train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73B_WFKy3iCK",
    "outputId": "7905433e-cf10-4e5f-9e37-a67f05bfed28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best particle {'learning_rate': 0.08691132105446604, 'subsample': 0.4939623033492828} with score 0.08892643429148894\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best particle {swarm_optimizer.global_best_particle} with score {swarm_optimizer.global_best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6b2yeenq3f4",
    "outputId": "7c139c01-d776-4f6a-b29a-6e5ecee82961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007392323683920141\n",
      "CPU times: user 2min 39s, sys: 254 ms, total: 2min 39s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_parameters = swarm_optimizer.global_best_particle\n",
    "\n",
    "final_model = XGBRegressor(objective='reg:squarederror', random_state=0, \n",
    "                           n_estimators=200, max_depth=10, **best_parameters)\n",
    "final_model.fit(perth_train.drop('log10_price', axis=1), perth_train['log10_price'])\n",
    "\n",
    "y = perth_test['log10_price']\n",
    "y_pred = final_model.predict(perth_test.drop('log10_price', axis=1))\n",
    "\n",
    "print(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27vp-L4irEE9",
    "outputId": "ce9fe17d-86b3-43ef-9fbd-82ae637454ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00724586724861683\n",
      "CPU times: user 2min 33s, sys: 133 ms, total: 2min 33s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Best parameters by genetic algorithm - 5 generations each with 20 population size (100 total)\n",
    "\n",
    "best_parameters = {'learning_rate': 0.06000000000000001, 'max_depth': 11, 'subsample': 0.7000000000000001}\n",
    "\n",
    "final_model = XGBRegressor(objective='reg:squarederror', random_state=0, n_estimators=200, **best_parameters)\n",
    "final_model.fit(perth_train.drop('log10_price', axis=1), perth_train['log10_price'])\n",
    "\n",
    "y = perth_test['log10_price']\n",
    "y_pred = final_model.predict(perth_test.drop('log10_price', axis=1))\n",
    "\n",
    "print(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1RO2fV2-yDM",
    "outputId": "7275280b-915c-406a-f68b-0bf810f7a6df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007313312056798277\n",
      "CPU times: user 2min, sys: 96.9 ms, total: 2min\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Best parameters by coordinate descent - 153 different models sampled\n",
    "\n",
    "best_parameters = {'learning_rate': 0.09, 'max_depth': 11, 'n_estimators': 170, 'subsample': 0.8}\n",
    "\n",
    "final_model = XGBRegressor(objective='reg:squarederror', random_state=0, **best_parameters)\n",
    "final_model.fit(perth_train.drop('log10_price', axis=1), perth_train['log10_price'])\n",
    "\n",
    "y = perth_test['log10_price']\n",
    "y_pred = final_model.predict(perth_test.drop('log10_price', axis=1))\n",
    "\n",
    "print(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgtRw0Ia-zwD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Particle Swarm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

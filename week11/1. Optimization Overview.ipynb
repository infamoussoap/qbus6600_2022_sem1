{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Optimzation is an incredibly diverse field that goes from very theoretical math to very applied applications. But they all rest on the same beginning. The idea with optimization is that we have some goal, call it $G$ and we want to try to find the optimal value $x$ that minimizes (or maximizes) that goal. This is typically written as such\n",
    "$$\\arg\\min_x\\ G(x)$$\n",
    "\n",
    "Importantly, this goal can be anything, for example one important use of optimization is how to get from point A to point B as fast as you can. In this case $x$ will be the different routes that one can take from A to B, and $G$ will be the time taken. So\n",
    "$$G(x) = \\textrm{Time taken to go from Point A to Point B using the route}\\ x$$\n",
    "Now this problem is known as the \"Shortest path problem\" and has been solved in many ways: Dijkstra's algorithm, Bellman-Ford, A*, etc.\n",
    "\n",
    "\n",
    "Really what interests us is where $x$ is the parameters of the model and $G$ is the validation (or CV) error\n",
    "$$G(x) = \\textrm{Validation error of a model with the parameters}\\ x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continous Problems\n",
    "\n",
    "One of the most simpliest optimization problems to slove is when $G(x)$ is continuous, and therefore it's derivative $G'(x)$ exists. \n",
    "\n",
    "### Simple Example - Classic 1st Year Calculus Example\n",
    "\n",
    "Find the dimensions of a rectangle such that it has the maximum area with a given perimeter of 10cm. In this case \n",
    "$$G(l, w) = \\textrm{Area of the rectangle that has a width of}\\ w\\ \\textrm{and height of}\\ l$$\n",
    "$$\\textrm{On the condition that}\\ 2l+2w=10$$\n",
    "\n",
    "Optimizing this is simple, since $2l+2w=10\\implies l+w=5\\implies w=5-l$\n",
    "$$G=lw=l(5-l)=5l-l^2$$\n",
    "Which is continuous and we can take the derivative of this:\n",
    "$$G'=5-2l=0\\implies l=\\frac{5}{2}=2.5$$\n",
    "Therefore the optimal length and width is $l=2.5$, and $w=2.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Aside\n",
    "\n",
    "Just to give some background, I have an undergraduate in applied mathematics so I have taken courses on \"optimization\". Time after time I am always disappointed by these courses, because while they do teach you optimization, it is always optimization on the most contrived, non-realistic examples that no-one will ever use in the real world.\n",
    "\n",
    "So the question I gave you before typically is shown as a a farmer who has 10km of fencing and they want to make an area as big as they can. BUT WHO CARES. Or they will give you an incredibly non-realistic example that will only exist in fantasy.\n",
    "\n",
    "The big issue that these problems all have is that the loss function is continuous and the derivative is easy to solve. But there are many situations, and even very simply situations, where you have a continuous function but the derivative is not so easy to solve. So what do you do then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex Example - Portfolio Optimization\n",
    "\n",
    "Let us consider portfolio optimization (Note that if you really care about portfolio optimization then what I'm doing here is very very inefficient. You should look at the Efficient Frountier if you really care about portfolio optimization).\n",
    "\n",
    "The aim of portfolio optimization is to maximize the returns of our portfolio, while minimizing the volatility. In math terms we can write this as\n",
    "\n",
    "$$G=\\mu - \\alpha \\sigma^2$$\n",
    "where $\\mu$ is the average returns of the portfolio and $\\sigma^2$ is the variance of the portfolio. And we want to maximize $G$. $\\alpha$ can be thought of as the risk tolerance (and regularization of sorts). If $\\alpha=0$ then all we care about is $G=\\mu$ and therefore we only care about maximizing the returns.\n",
    "\n",
    "If we think back to regularization, when $\\alpha=0$ (i.e. the regularization strentgh = 0) then the model is overfitting. In portfolio optimization overfitting is maximizing returns. When $\\alpha$ gets bigger, (i.e. the regularization strength increase) we expect models to underfit. In the same sense, we should expect the portfolio returns to be smaller, but the volatility is also smaller as well.\n",
    "\n",
    "Now when $\\alpha>0$ it means that we want to care about the volatility, and so we want to find the optimal returns at a given level of volatility. So $\\alpha$ can be thought of as the risk tolerance, when $\\alpha$ is small we have a high risk tolerance (we only care about returns), but when $\\alpha$ is big we have a very low risk tolerance. \n",
    "\n",
    "But the main goal in portfolio optimization is to say, given a risk tolerance $\\alpha$ what is the optimal returns of my portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping it simple, consider my portfolio consisted of only 2 stocks, where $r_1^t$ is the returns of asset 1 at time $t$ and $r_2^t$ is the returns of asset 2 at time $t$. Let $w\\in[0,1]$ be the weighting of asset 1, and therefore $1-w$ is the weighting of asset 2. (For example if $w=0.2$ then the portfolio consists of $20\\%$ asset 1 and $80\\%$ asset 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the portfolio returns at time $t$\n",
    "$$R_t=wr_1^t + (1-w)r_2^t$$\n",
    "\n",
    "So we want to maximize\n",
    "$$G = \\mu - \\alpha \\sigma^2$$\n",
    "Where \n",
    "$$\\mu=\\frac{1}{T}\\sum_{t=1}^TR_t \\quad \\sigma^2=\\frac{1}{T}\\sum_{t=1}^T (R_t-\\mu)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following from before, we can just take the derivative of $G$ with respect to the weight $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial G}{\\partial w}=\\frac{\\partial \\mu}{\\partial w}-\\alpha\\frac{\\partial \\sigma^2}{\\partial w}$$\n",
    "\n",
    "\n",
    "Now \n",
    "$$\\frac{\\partial \\mu}{\\partial w}=\\frac{1}{T}\\sum_t\\frac{\\partial R_t}{\\partial w}=\\frac{1}{T}\\sum_t(r_1^t-r_2^t)$$\n",
    "\n",
    "Likewise, by using the chain rule\n",
    "$$\\frac{\\partial \\sigma^2}{\\partial w}=\\frac{2}{T}\\sum_t(R_t - \\mu)\\bigg(\\frac{\\partial R_t}{\\partial w} - \\frac{\\partial \\mu}{\\partial w}\\bigg)=\\frac{2}{T}\\sum_t (R_t-\\mu)(r_1^t-r_2^t-\\frac{\\partial \\mu}{\\partial w})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in total\n",
    "\n",
    "$$\\frac{\\partial G}{\\partial w} = \\frac{1}{T}\\sum_t(r_1^t-r_2^t) - \\alpha \\bigg[\\frac{2}{T}\\sum_t (R_t-\\mu)(r_1^t-r_2^t-\\frac{\\partial \\mu}{\\partial w})\\bigg]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a horrible expression to try and I dare you to try and solve it equal to 0. So we do something else instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to recap, here we have a problem where we can take the derivative with respect to the inputs. But the problem is that solving\n",
    "$$\\frac{\\partial G}{\\partial w}=0$$\n",
    "is just too difficult. So this is a situation where the gradients exists, but too diffcult to solve. So instead we do something different, we will use gradient descent.\n",
    "\n",
    "As an aside, I use TensorFlow because that was what was popular when I started machine learning like 6 years ago. But now people like to use PyTorch, so don't use TensorFlow, use PyTorch. Don't be like me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import yfinance as yf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    }
   ],
   "source": [
    "start = datetime.date(2020, 1, 1)\n",
    "end = datetime.date(2021, 1, 1)\n",
    "\n",
    "ticker = yf.Tickers(\"MSFT AAPL\")\n",
    "close_history = ticker.history(start=start, end=end)[\"Close\"]\n",
    "\n",
    "returns = np.log(close_history).diff().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>0.022560</td>\n",
       "      <td>0.018347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>-0.009770</td>\n",
       "      <td>-0.012530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>-0.004714</td>\n",
       "      <td>-0.009160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.015803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      MSFT\n",
       "Date                          \n",
       "2020-01-02  0.022560  0.018347\n",
       "2020-01-03 -0.009770 -0.012530\n",
       "2020-01-06  0.007937  0.002581\n",
       "2020-01-07 -0.004714 -0.009160\n",
       "2020-01-08  0.015958  0.015803"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you compute gradients using tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.002503505>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 10\n",
    "w = tf.constant(0.0)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(w)\n",
    "    \n",
    "    R_t = w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"]\n",
    "    mu = tf.reduce_mean(R_t)\n",
    "    std = tf.reduce_mean((R_t - mu) ** 2)\n",
    "    \n",
    "    G = mu - alpha * std\n",
    "    \n",
    "dG_dw = g.gradient(G, w)\n",
    "dG_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "learning_rate = 100\n",
    "\n",
    "w = tf.constant(0.0)\n",
    "history = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(w)\n",
    "                \n",
    "        R_t = w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"]\n",
    "        mu = tf.reduce_mean(R_t)\n",
    "        std = tf.reduce_mean((R_t - mu) ** 2)\n",
    "\n",
    "        G = mu - alpha * std\n",
    "\n",
    "    dG_dw = g.gradient(G, w)\n",
    "    \n",
    "    # Note that we want to maximize G here, not minimize. \n",
    "    # -= will minimize the loss function while += will maximize\n",
    "    w += learning_rate * dG_dw\n",
    "    history.append(w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48860517"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is saying that the optimal weight for our portfolio is $w=0.488$, and this weight is the weight that will give the highest returns for the risk tolerance $\\alpha=10$! How cool! We didn't even need to do complex math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "learning_rate = 100\n",
    "\n",
    "w = tf.constant(0.0)\n",
    "history = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(w)\n",
    "                \n",
    "        R_t = w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"]\n",
    "        mu = tf.reduce_mean(R_t)\n",
    "        std = tf.reduce_mean((R_t - mu) ** 2)\n",
    "\n",
    "        G = mu - alpha * std\n",
    "\n",
    "    dG_dw = g.gradient(G, w)\n",
    "    \n",
    "    w += learning_rate * dG_dw\n",
    "    history.append(w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history)\n",
    "plt.title(f\"Alpha = {alpha}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.30398"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, this is now saying that the optimal weight for the risk tolerance $\\alpha=1$ is $w=-1.30$. Let's see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0038\n",
      "Var : 0.0018\n"
     ]
    }
   ],
   "source": [
    "# Optimal w for alpha=1\n",
    "w = -1.3532923\n",
    "\n",
    "mu = np.mean(w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"])\n",
    "var = np.var(w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"])\n",
    "\n",
    "print(\"Mean:\", round(mu, 4))\n",
    "print(\"Var :\", round(var, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0019\n",
      "Var : 0.0008\n"
     ]
    }
   ],
   "source": [
    "# Optimal w for alpha=10\n",
    "w = 0.48860407\n",
    "\n",
    "mu = np.mean(w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"])\n",
    "var = np.var(w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"])\n",
    "\n",
    "print(\"Mean:\", round(mu, 4))\n",
    "print(\"Var :\", round(var, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well first we can see that our optimization works as expected. When $\\alpha$ increases (i.e. the risk tolerance) the variance of the portfolio decreases, but the returns also decrease as well.\n",
    "\n",
    "But a negative weight basically means that we allow our portfolio to have short positions, which further increases the riskyness of the portfolio. But this can be fixed easily by re-writing the optimization problem as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the portfolio returns at time $t$\n",
    "$$R_t=r_1^t + (1-w)r_2^t, \\quad \\textrm{where}\\ w = \\textrm{Sigmoid}(\\theta).$$\n",
    "\n",
    "So we want to maximize\n",
    "$$G = \\mu - \\alpha \\sigma^2$$\n",
    "Where \n",
    "$$\\mu=\\frac{1}{T}\\sum_{t=1}^TR_t \\quad \\sigma^2=\\frac{1}{T}\\sum_{t=1}^T (R_t-\\mu)^2$$\n",
    "\n",
    "Notice we just simply place an intermediate step $w=\\textrm{Sigmoid}(\\theta)$. But this intermediate step ensures that $w\\in(0,1)$ and is not negative. But the important thing here is that rather than taking the derivative with respect to $w$ we take the derivative with respect to $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "learning_rate = 100\n",
    "\n",
    "ùúÉ = tf.constant(0.1)\n",
    "history = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(ùúÉ)\n",
    "        \n",
    "        w = tf.math.sigmoid(ùúÉ)\n",
    "                \n",
    "        R_t = w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"]\n",
    "        mu = tf.reduce_mean(R_t)\n",
    "        std = tf.reduce_mean((R_t - mu) ** 2)\n",
    "\n",
    "        G = mu - alpha * std\n",
    "\n",
    "    dG_dùúÉ = g.gradient(G, ùúÉ)\n",
    "    \n",
    "    ùúÉ += learning_rate * dG_dùúÉ\n",
    "    history.append(tf.math.sigmoid(ùúÉ).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48860553"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, because 0.488 was the exact same value as what we got before we did the intermediate step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "learning_rate = 300\n",
    "\n",
    "ùúÉ = tf.constant(0.1)\n",
    "history = []\n",
    "\n",
    "for _ in range(4000):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(ùúÉ)\n",
    "        \n",
    "        w = tf.math.sigmoid(ùúÉ)\n",
    "                \n",
    "        R_t = w * returns[\"MSFT\"] + (1 - w) * returns[\"AAPL\"]\n",
    "        mu = tf.reduce_mean(R_t)\n",
    "        std = tf.reduce_mean((R_t - mu) ** 2)\n",
    "\n",
    "        G = mu - alpha * std\n",
    "\n",
    "    dG_dùúÉ = g.gradient(G, ùúÉ)\n",
    "    \n",
    "    ùúÉ += learning_rate * dG_dùúÉ\n",
    "    history.append(tf.math.sigmoid(ùúÉ).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012576878"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically this is saying that $w=0$, and so we only want asset 2 (AAPL) in our portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "So that is basically it for continuous optimization. There is a bit more I can talk about, like the differences between (stochastic) gradient descent vs. RMSProp vs. ADAM, as well as Newton's method. But that basically completes continuous optimization.\n",
    "\n",
    "But just to quickly review what just happened. Let's say that we have a optimization problem $G(x)$ and we are lucky enough that $G$ has derivatives. Then\n",
    "1. If we can solve $\\partial G/\\partial x=0$ then this is good. We have gauranted optimal solution.\n",
    "2. However, as shown here, there are a lot of problems where this equation ($\\partial G/\\partial x=0$) cannot be solved. But since it's gradients exist we can use gradient descent to solve it. Of course, gradient descent has it's own problems, but I won't get into that here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Continuous Problems\n",
    "\n",
    "That's good and all, but what happens if the problem that I have has no derivatives. Going back to the introduction where the goal is to go from Point A to Point B as quick as you can, there is no way you can take the derivative with respect to the different paths. Another example is trying to find the best move in a Chess game, or a game like LOL. There is simply no way that these problems are continuous. \n",
    "\n",
    "So how do I solve this?\n",
    "\n",
    "### The Key to Optimization\n",
    "The key to all optimization is to exploit any information about the problem you have at hand. \n",
    "\n",
    "- In the case of continuous problems, we are going to exploit the fact that we can compute the derivatives. We will then use the derivatives to find the optimal solution\n",
    "- In the case of the Shortest Path Problem, and optimal Chess/LOL move, you can exploit the fact that these can be modeled as graphs. Since these exists on a graph you can use things like Bellman-Ford, A*, etc. But that's not relevant to us here.\n",
    "\n",
    "However, for this course we really are interested in find the hyper-parameters that give the best validation or CV error. The hyper-parameters are definetely not differentiable, nor do they exist on a graph. Really there is no information to exploit.\n",
    "\n",
    "So the question is now, how do we optimize something where there is no information to exploit about them. To solve this we will look at meta-heuristic algorithms. Meta-heuristic algorithms simply try to optimize your loss function, but the key is that the make very little assumptions about the problem you are trying to solve. \n",
    "\n",
    "Because they make so little assumptions they can be used on a wide variety of problems. However, there is **no gaurantee** that the optimum solution can be found. As such, in theory, one can use meta-heuristics algorithms on continuous problems or even on the shortest path problem, but there is no gaurantee that the optimum solution can or will be found. In contrast, when we exploit the fact that gradients exist, or that the problem exists on a graph we can gaurantees on finding the optimum solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless, taking from Wikipedia\n",
    "\n",
    "    Metaheuristics sample a subset of solutions which is otherwise too large to be completely enumerated or otherwise explored.\n",
    "    \n",
    "    [M]etaheuristics can often find good solutions with less computational effort than optimization algorithms, iterative methods, or simple heuristics. As such, they are useful approaches for optimization problems\n",
    "    \n",
    "Just giving some examples of the algorithms they are comparing to\n",
    "- Optimization Algorithms: Grid Search/Randomized Search\n",
    "- Iterative Methods: Coordinate descent\n",
    "- Simple Heuristics: Greedy search\n",
    "\n",
    "Again from Wikipedia\n",
    "\n",
    "    These are properties that characterize most metaheuristics:[3]\n",
    "        - Metaheuristics are strategies that guide the search process.\n",
    "        - The goal is to efficiently explore the search space in order to find near‚Äìoptimal solutions.\n",
    "        - Metaheuristic algorithms are approximate and usually non-deterministic.\n",
    "        - Metaheuristics are not problem-specific.\n",
    "\n",
    "The important point to highlight is that metaheuristic algorithms are non-deterministic. Meaning that when everytime you run the algorithm you may actually get different results. This is because, at least for the algoithms that we will look at, there is a level of randomness that is inherent to these algorithms.\n",
    "\n",
    "Regardless, we will be looking at three of the most popular meta-heuristic algorithms (1) Genetic Algorithms and (2) Simulated Annealing and (if we have time) (3) Particle Swarm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V4JgREh7UuPS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "np61ldeJU7er"
   },
   "outputs": [],
   "source": [
    "perth = pd.read_csv('perth_clean.csv')\n",
    "perth = pd.get_dummies(perth, columns=['suburb'])\n",
    "\n",
    "train_indices, test_indices = train_test_split(perth.index, test_size=0.2, random_state=0)\n",
    "\n",
    "perth_train = perth.loc[train_indices].copy()\n",
    "perth_test = perth.loc[test_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lU58QCba5Q6",
    "outputId": "6be87aba-d2b9-4ac9-a1b6-482ddd49fe3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length 26924\n",
      "Tresting set length 6732\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length\", len(perth_train))\n",
    "print(\"Tresting set length\", len(perth_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhO2JfwgU86E",
    "outputId": "580c0889-cdbc-497e-9537-7c79e0d38c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Training set length 5384\n"
     ]
    }
   ],
   "source": [
    "indices = list(perth_train.index.copy())\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "sampled_indices = indices[:int(len(indices) * 0.2)]\n",
    "sampled_perth_train = perth_train.loc[sampled_indices, :].copy()\n",
    "\n",
    "print(\"Sampled Training set length\", len(sampled_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WtgAVvbU-7-",
    "outputId": "5875cd6d-70d3-46a8-dc2a-bb45c072a721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training length of sampled data 4307\n",
      "Validiation length of sampled data 1077\n"
     ]
    }
   ],
   "source": [
    "n = len(sampled_perth_train)\n",
    "sampled_train_indices, sampled_valid_indices = train_test_split(np.arange(n), test_size=0.2, random_state=0)\n",
    "\n",
    "sampled_x_train = sampled_perth_train.drop('log10_price', axis=1)\n",
    "sampled_y_train = sampled_perth_train['log10_price']\n",
    "\n",
    "print(\"Training length of sampled data\", len(sampled_train_indices))\n",
    "print(\"Validiation length of sampled data\", len(sampled_valid_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqDtl4tKVBCV"
   },
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "QcV3yz_mVB21"
   },
   "outputs": [],
   "source": [
    "parameter_grid = {'min_samples_leaf': np.arange(1, 100, 5),\n",
    "                  'max_features': np.arange(1, len(perth_train.columns) - 1, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M81zWb0RVEbY",
    "outputId": "e6fc4b68-4e8f-4e7d-9684-8aae7b72c779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 159 candidates, totalling 159 fits\n",
      "[CV 1/1] END max_features=281, min_samples_leaf=31;, score=-0.013 total time=   3.4s\n",
      "[CV 1/1] END max_features=41, min_samples_leaf=21;, score=-0.020 total time=   0.6s\n",
      "[CV 1/1] END max_features=51, min_samples_leaf=86;, score=-0.023 total time=   0.6s\n",
      "[CV 1/1] END max_features=56, min_samples_leaf=36;, score=-0.019 total time=   0.8s\n",
      "[CV 1/1] END max_features=86, min_samples_leaf=26;, score=-0.014 total time=   1.3s\n",
      "[CV 1/1] END max_features=291, min_samples_leaf=61;, score=-0.016 total time=   3.1s\n",
      "[CV 1/1] END max_features=201, min_samples_leaf=46;, score=-0.014 total time=   2.4s\n",
      "[CV 1/1] END max_features=21, min_samples_leaf=46;, score=-0.034 total time=   0.3s\n",
      "[CV 1/1] END max_features=181, min_samples_leaf=81;, score=-0.017 total time=   1.9s\n",
      "[CV 1/1] END max_features=316, min_samples_leaf=36;, score=-0.014 total time=   3.7s\n",
      "[CV 1/1] END max_features=291, min_samples_leaf=1;, score=-0.010 total time=   7.1s\n",
      "[CV 1/1] END max_features=21, min_samples_leaf=6;, score=-0.016 total time=   0.7s\n",
      "[CV 1/1] END max_features=201, min_samples_leaf=61;, score=-0.016 total time=   2.2s\n",
      "[CV 1/1] END max_features=256, min_samples_leaf=66;, score=-0.016 total time=   2.7s\n",
      "[CV 1/1] END max_features=106, min_samples_leaf=41;, score=-0.014 total time=   1.5s\n",
      "[CV 1/1] END max_features=156, min_samples_leaf=16;, score=-0.012 total time=   2.3s\n",
      "[CV 1/1] END max_features=271, min_samples_leaf=26;, score=-0.013 total time=   3.3s\n",
      "[CV 1/1] END max_features=51, min_samples_leaf=61;, score=-0.022 total time=   0.6s\n",
      "[CV 1/1] END max_features=306, min_samples_leaf=76;, score=-0.017 total time=   3.0s\n",
      "[CV 1/1] END max_features=181, min_samples_leaf=71;, score=-0.016 total time=   1.9s\n",
      "[CV 1/1] END max_features=146, min_samples_leaf=76;, score=-0.017 total time=   1.6s\n",
      "[CV 1/1] END max_features=171, min_samples_leaf=6;, score=-0.010 total time=   3.0s\n",
      "[CV 1/1] END max_features=26, min_samples_leaf=51;, score=-0.031 total time=   0.4s\n",
      "[CV 1/1] END max_features=286, min_samples_leaf=96;, score=-0.018 total time=   2.6s\n",
      "[CV 1/1] END max_features=81, min_samples_leaf=56;, score=-0.017 total time=   1.1s\n",
      "[CV 1/1] END max_features=56, min_samples_leaf=86;, score=-0.022 total time=   0.7s\n",
      "[CV 1/1] END max_features=151, min_samples_leaf=81;, score=-0.017 total time=   1.6s\n",
      "[CV 1/1] END max_features=26, min_samples_leaf=61;, score=-0.032 total time=   0.3s\n",
      "[CV 1/1] END max_features=146, min_samples_leaf=81;, score=-0.017 total time=   1.5s\n",
      "[CV 1/1] END max_features=26, min_samples_leaf=41;, score=-0.030 total time=   0.4s\n",
      "[CV 1/1] END max_features=61, min_samples_leaf=36;, score=-0.017 total time=   0.9s\n",
      "[CV 1/1] END max_features=71, min_samples_leaf=86;, score=-0.020 total time=   0.8s\n",
      "[CV 1/1] END max_features=326, min_samples_leaf=6;, score=-0.011 total time=   5.0s\n",
      "[CV 1/1] END max_features=256, min_samples_leaf=61;, score=-0.016 total time=   2.7s\n",
      "[CV 1/1] END max_features=136, min_samples_leaf=11;, score=-0.011 total time=   2.2s\n",
      "[CV 1/1] END max_features=286, min_samples_leaf=11;, score=-0.011 total time=   4.0s\n",
      "[CV 1/1] END max_features=71, min_samples_leaf=51;, score=-0.018 total time=   0.9s\n",
      "[CV 1/1] END max_features=86, min_samples_leaf=1;, score=-0.009 total time=   2.9s\n",
      "[CV 1/1] END max_features=16, min_samples_leaf=46;, score=-0.037 total time=   0.3s\n",
      "[CV 1/1] END max_features=146, min_samples_leaf=66;, score=-0.016 total time=   1.7s\n",
      "[CV 1/1] END max_features=56, min_samples_leaf=71;, score=-0.021 total time=   0.7s\n",
      "[CV 1/1] END max_features=311, min_samples_leaf=51;, score=-0.015 total time=   3.3s\n",
      "[CV 1/1] END max_features=96, min_samples_leaf=91;, score=-0.018 total time=   1.1s\n",
      "[CV 1/1] END max_features=151, min_samples_leaf=26;, score=-0.013 total time=   2.0s\n",
      "[CV 1/1] END max_features=121, min_samples_leaf=6;, score=-0.010 total time=   2.2s\n",
      "[CV 1/1] END max_features=171, min_samples_leaf=11;, score=-0.011 total time=   2.7s\n",
      "[CV 1/1] END max_features=101, min_samples_leaf=16;, score=-0.012 total time=   1.6s\n",
      "[CV 1/1] END max_features=136, min_samples_leaf=66;, score=-0.016 total time=   1.6s\n",
      "[CV 1/1] END max_features=161, min_samples_leaf=96;, score=-0.018 total time=   1.6s\n",
      "[CV 1/1] END max_features=266, min_samples_leaf=61;, score=-0.016 total time=   2.7s\n",
      "[CV 1/1] END max_features=181, min_samples_leaf=16;, score=-0.012 total time=   2.6s\n",
      "[CV 1/1] END max_features=26, min_samples_leaf=46;, score=-0.031 total time=   0.3s\n",
      "[CV 1/1] END max_features=156, min_samples_leaf=91;, score=-0.018 total time=   1.6s\n",
      "[CV 1/1] END max_features=331, min_samples_leaf=11;, score=-0.012 total time=   4.5s\n",
      "[CV 1/1] END max_features=26, min_samples_leaf=21;, score=-0.029 total time=   0.3s\n",
      "[CV 1/1] END max_features=251, min_samples_leaf=66;, score=-0.016 total time=   2.6s\n",
      "[CV 1/1] END max_features=261, min_samples_leaf=56;, score=-0.015 total time=   2.8s\n",
      "[CV 1/1] END max_features=136, min_samples_leaf=56;, score=-0.015 total time=   1.6s\n",
      "[CV 1/1] END max_features=151, min_samples_leaf=56;, score=-0.015 total time=   1.8s\n",
      "[CV 1/1] END max_features=1, min_samples_leaf=76;, score=-0.044 total time=   0.2s\n",
      "[CV 1/1] END max_features=181, min_samples_leaf=96;, score=-0.018 total time=   1.7s\n",
      "[CV 1/1] END max_features=321, min_samples_leaf=31;, score=-0.014 total time=   3.8s\n",
      "[CV 1/1] END max_features=31, min_samples_leaf=56;, score=-0.029 total time=   0.4s\n",
      "[CV 1/1] END max_features=191, min_samples_leaf=6;, score=-0.010 total time=   3.3s\n",
      "[CV 1/1] END max_features=111, min_samples_leaf=1;, score=-0.009 total time=   3.4s\n",
      "[CV 1/1] END max_features=11, min_samples_leaf=66;, score=-0.039 total time=   0.2s\n",
      "[CV 1/1] END max_features=186, min_samples_leaf=91;, score=-0.018 total time=   1.9s\n",
      "[CV 1/1] END max_features=106, min_samples_leaf=46;, score=-0.015 total time=   1.3s\n",
      "[CV 1/1] END max_features=321, min_samples_leaf=56;, score=-0.016 total time=   3.3s\n",
      "[CV 1/1] END max_features=171, min_samples_leaf=51;, score=-0.015 total time=   2.0s\n",
      "[CV 1/1] END max_features=316, min_samples_leaf=11;, score=-0.011 total time=   4.3s\n",
      "[CV 1/1] END max_features=136, min_samples_leaf=36;, score=-0.014 total time=   1.7s\n",
      "[CV 1/1] END max_features=71, min_samples_leaf=11;, score=-0.012 total time=   1.3s\n",
      "[CV 1/1] END max_features=26, min_samples_leaf=66;, score=-0.032 total time=   0.3s\n",
      "[CV 1/1] END max_features=231, min_samples_leaf=96;, score=-0.018 total time=   2.2s\n",
      "[CV 1/1] END max_features=181, min_samples_leaf=31;, score=-0.013 total time=   2.3s\n",
      "[CV 1/1] END max_features=246, min_samples_leaf=91;, score=-0.018 total time=   2.3s\n",
      "[CV 1/1] END max_features=156, min_samples_leaf=61;, score=-0.016 total time=   1.7s\n",
      "[CV 1/1] END max_features=71, min_samples_leaf=16;, score=-0.013 total time=   1.2s\n",
      "[CV 1/1] END max_features=151, min_samples_leaf=76;, score=-0.017 total time=   1.6s\n",
      "[CV 1/1] END max_features=71, min_samples_leaf=36;, score=-0.016 total time=   1.0s\n",
      "[CV 1/1] END max_features=121, min_samples_leaf=76;, score=-0.017 total time=   1.4s\n",
      "[CV 1/1] END max_features=36, min_samples_leaf=16;, score=-0.019 total time=   0.6s\n",
      "[CV 1/1] END max_features=61, min_samples_leaf=56;, score=-0.019 total time=   0.8s\n",
      "[CV 1/1] END max_features=101, min_samples_leaf=71;, score=-0.017 total time=   1.2s\n",
      "[CV 1/1] END max_features=226, min_samples_leaf=51;, score=-0.015 total time=   2.5s\n",
      "[CV 1/1] END max_features=71, min_samples_leaf=56;, score=-0.018 total time=   0.9s\n",
      "[CV 1/1] END max_features=61, min_samples_leaf=11;, score=-0.013 total time=   1.2s\n",
      "[CV 1/1] END max_features=96, min_samples_leaf=66;, score=-0.017 total time=   1.1s\n",
      "[CV 1/1] END max_features=16, min_samples_leaf=66;, score=-0.037 total time=   0.2s\n",
      "[CV 1/1] END max_features=196, min_samples_leaf=81;, score=-0.017 total time=   2.0s\n",
      "[CV 1/1] END max_features=91, min_samples_leaf=51;, score=-0.015 total time=   1.2s\n",
      "[CV 1/1] END max_features=46, min_samples_leaf=36;, score=-0.021 total time=   0.6s\n",
      "[CV 1/1] END max_features=166, min_samples_leaf=21;, score=-0.012 total time=   2.2s\n",
      "[CV 1/1] END max_features=276, min_samples_leaf=46;, score=-0.015 total time=   3.1s\n",
      "[CV 1/1] END max_features=31, min_samples_leaf=1;, score=-0.010 total time=   1.7s\n",
      "[CV 1/1] END max_features=311, min_samples_leaf=76;, score=-0.017 total time=   2.9s\n",
      "[CV 1/1] END max_features=136, min_samples_leaf=6;, score=-0.010 total time=   2.4s\n",
      "[CV 1/1] END max_features=51, min_samples_leaf=71;, score=-0.023 total time=   0.6s\n",
      "[CV 1/1] END max_features=171, min_samples_leaf=21;, score=-0.012 total time=   2.4s\n",
      "[CV 1/1] END max_features=106, min_samples_leaf=96;, score=-0.018 total time=   1.1s\n",
      "[CV 1/1] END max_features=121, min_samples_leaf=16;, score=-0.012 total time=   1.9s\n",
      "[CV 1/1] END max_features=316, min_samples_leaf=81;, score=-0.018 total time=   3.0s\n",
      "[CV 1/1] END max_features=231, min_samples_leaf=41;, score=-0.014 total time=   2.7s\n",
      "[CV 1/1] END max_features=326, min_samples_leaf=86;, score=-0.018 total time=   3.0s\n",
      "[CV 1/1] END max_features=251, min_samples_leaf=26;, score=-0.013 total time=   3.1s\n",
      "[CV 1/1] END max_features=296, min_samples_leaf=51;, score=-0.015 total time=   3.2s\n",
      "[CV 1/1] END max_features=96, min_samples_leaf=76;, score=-0.017 total time=   1.1s\n",
      "[CV 1/1] END max_features=201, min_samples_leaf=21;, score=-0.012 total time=   2.6s\n",
      "[CV 1/1] END max_features=206, min_samples_leaf=81;, score=-0.017 total time=   2.0s\n",
      "[CV 1/1] END max_features=106, min_samples_leaf=66;, score=-0.017 total time=   1.3s\n",
      "[CV 1/1] END max_features=271, min_samples_leaf=66;, score=-0.016 total time=   2.7s\n",
      "[CV 1/1] END max_features=276, min_samples_leaf=96;, score=-0.018 total time=   2.4s\n",
      "[CV 1/1] END max_features=116, min_samples_leaf=56;, score=-0.015 total time=   1.4s\n",
      "[CV 1/1] END max_features=51, min_samples_leaf=21;, score=-0.018 total time=   0.8s\n",
      "[CV 1/1] END max_features=191, min_samples_leaf=1;, score=-0.009 total time=   5.0s\n",
      "[CV 1/1] END max_features=41, min_samples_leaf=76;, score=-0.024 total time=   0.5s\n",
      "[CV 1/1] END max_features=221, min_samples_leaf=81;, score=-0.017 total time=   2.2s\n",
      "[CV 1/1] END max_features=1, min_samples_leaf=71;, score=-0.044 total time=   0.2s\n",
      "[CV 1/1] END max_features=66, min_samples_leaf=16;, score=-0.013 total time=   1.1s\n",
      "[CV 1/1] END max_features=21, min_samples_leaf=11;, score=-0.020 total time=   0.5s\n",
      "[CV 1/1] END max_features=106, min_samples_leaf=56;, score=-0.016 total time=   1.3s\n",
      "[CV 1/1] END max_features=96, min_samples_leaf=46;, score=-0.015 total time=   1.3s\n",
      "[CV 1/1] END max_features=206, min_samples_leaf=31;, score=-0.013 total time=   2.6s\n",
      "[CV 1/1] END max_features=301, min_samples_leaf=76;, score=-0.017 total time=   2.9s\n",
      "[CV 1/1] END max_features=151, min_samples_leaf=86;, score=-0.018 total time=   1.5s\n",
      "[CV 1/1] END max_features=211, min_samples_leaf=71;, score=-0.016 total time=   2.2s\n",
      "[CV 1/1] END max_features=121, min_samples_leaf=71;, score=-0.017 total time=   1.4s\n",
      "[CV 1/1] END max_features=21, min_samples_leaf=66;, score=-0.035 total time=   0.3s\n",
      "[CV 1/1] END max_features=256, min_samples_leaf=16;, score=-0.012 total time=   3.5s\n",
      "[CV 1/1] END max_features=191, min_samples_leaf=21;, score=-0.012 total time=   2.6s\n",
      "[CV 1/1] END max_features=166, min_samples_leaf=36;, score=-0.013 total time=   2.0s\n",
      "[CV 1/1] END max_features=261, min_samples_leaf=96;, score=-0.018 total time=   2.4s\n",
      "[CV 1/1] END max_features=331, min_samples_leaf=21;, score=-0.013 total time=   4.0s\n",
      "[CV 1/1] END max_features=241, min_samples_leaf=41;, score=-0.014 total time=   2.8s\n",
      "[CV 1/1] END max_features=276, min_samples_leaf=21;, score=-0.013 total time=   3.5s\n",
      "[CV 1/1] END max_features=316, min_samples_leaf=46;, score=-0.015 total time=   3.5s\n",
      "[CV 1/1] END max_features=201, min_samples_leaf=76;, score=-0.017 total time=   2.0s\n",
      "[CV 1/1] END max_features=51, min_samples_leaf=1;, score=-0.010 total time=   2.2s\n",
      "[CV 1/1] END max_features=6, min_samples_leaf=66;, score=-0.042 total time=   0.2s\n",
      "[CV 1/1] END max_features=26, min_samples_leaf=81;, score=-0.032 total time=   0.3s\n",
      "[CV 1/1] END max_features=141, min_samples_leaf=46;, score=-0.014 total time=   1.7s\n",
      "[CV 1/1] END max_features=11, min_samples_leaf=96;, score=-0.039 total time=   0.2s\n",
      "[CV 1/1] END max_features=306, min_samples_leaf=91;, score=-0.018 total time=   2.8s\n",
      "[CV 1/1] END max_features=171, min_samples_leaf=36;, score=-0.013 total time=   2.1s\n",
      "[CV 1/1] END max_features=286, min_samples_leaf=56;, score=-0.015 total time=   3.0s\n",
      "[CV 1/1] END max_features=166, min_samples_leaf=96;, score=-0.018 total time=   1.6s\n",
      "[CV 1/1] END max_features=101, min_samples_leaf=81;, score=-0.018 total time=   1.2s\n",
      "[CV 1/1] END max_features=326, min_samples_leaf=61;, score=-0.016 total time=   3.3s\n",
      "[CV 1/1] END max_features=306, min_samples_leaf=71;, score=-0.017 total time=   2.9s\n",
      "[CV 1/1] END max_features=271, min_samples_leaf=31;, score=-0.013 total time=   3.3s\n",
      "[CV 1/1] END max_features=246, min_samples_leaf=46;, score=-0.014 total time=   2.7s\n",
      "[CV 1/1] END max_features=51, min_samples_leaf=6;, score=-0.012 total time=   1.3s\n",
      "[CV 1/1] END max_features=261, min_samples_leaf=51;, score=-0.015 total time=   2.8s\n",
      "[CV 1/1] END max_features=31, min_samples_leaf=71;, score=-0.030 total time=   0.3s\n",
      "[CV 1/1] END max_features=306, min_samples_leaf=56;, score=-0.015 total time=   3.1s\n",
      "[CV 1/1] END max_features=271, min_samples_leaf=96;, score=-0.018 total time=   2.4s\n",
      "[CV 1/1] END max_features=231, min_samples_leaf=26;, score=-0.013 total time=   2.9s\n",
      "[CV 1/1] END max_features=21, min_samples_leaf=56;, score=-0.035 total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=[(array([ 639, 2724, 5105, ..., 1653, 2607, 2732]),\n",
       "                        array([ 499, 3624, 2104, ..., 2584, 1363, 2744]))],\n",
       "                   estimator=RandomForestRegressor(random_state=0), n_iter=159,\n",
       "                   param_distributions={'max_features': array([  1,   6,  11,  16,  21,  26,  31,  36,  41,  46,  51,  56,  61,\n",
       "        66,  71,  76,  81,  86,  91,  96, 101, 106, 111, 116, 121, 126,\n",
       "       131, 136, 141, 146, 151, 156, 161, 166, 171, 176, 181, 186, 191,\n",
       "       196, 201, 206, 211, 216, 221, 226, 231, 236, 241, 246, 251, 256,\n",
       "       261, 266, 271, 276, 281, 286, 291, 296, 301, 306, 311, 316, 321,\n",
       "       326, 331]),\n",
       "                                        'min_samples_leaf': array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81,\n",
       "       86, 91, 96])},\n",
       "                   refit=False, scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(criterion='squared_error', random_state=0)\n",
    "\n",
    "search = RandomizedSearchCV(base_model, parameter_grid, \n",
    "                            cv=[(sampled_train_indices, sampled_valid_indices)], \n",
    "                            n_iter=(20 + 67 + 5 + 67),\n",
    "                            scoring=\"neg_mean_squared_error\", verbose=3, refit=False)\n",
    "\n",
    "search.fit(sampled_x_train, sampled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xA1i3wPMVkr4",
    "outputId": "79d3faab-0fdb-4128-de32-e31220110f39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 191, 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mjWmMhtWFRo",
    "outputId": "871348fb-bba1-46de-ff65-d66006aafa51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007857488928888677\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestRegressor(criterion='squared_error', random_state=0, **search.best_params_)\n",
    "final_model.fit(perth_train.drop('log10_price', axis=1), perth_train['log10_price'])\n",
    "\n",
    "y = perth_test['log10_price']\n",
    "y_pred = final_model.predict(perth_test.drop('log10_price', axis=1))\n",
    "print(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sqWlRwFWJO8",
    "outputId": "3b3d7f28-31aa-43f6-9f67-acba2734d313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00781962457241284\n"
     ]
    }
   ],
   "source": [
    "# Best Parameteres from Coordinate Descentib \n",
    "base_parameters = {'max_features': 106, 'min_samples_leaf': 1}\n",
    "\n",
    "final_model = RandomForestRegressor(criterion='squared_error', random_state=0, **base_parameters)\n",
    "final_model.fit(perth_train.drop('log10_price', axis=1), perth_train['log10_price'])\n",
    "\n",
    "y = perth_test['log10_price']\n",
    "y_pred = final_model.predict(perth_test.drop('log10_price', axis=1))\n",
    "print(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "druvtEPDWjTJ"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "9CpNkCZmWWow"
   },
   "outputs": [],
   "source": [
    "parameter_grid = {'n_estimators': np.arange(50, 200 + 1, 10),\n",
    "                  'learning_rate': np.linspace(0.01, 0.10, 10),\n",
    "                  'max_depth': np.arange(1, 100 + 1, 10),\n",
    "                  'subsample': np.linspace(0.1, 1.0, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGb0wnXGWlR9",
    "outputId": "4c850b15-b342-41ef-e788-03d90e8e1414"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 10, 10, 10]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(val) for val in parameter_grid.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xqn36vyWml7",
    "outputId": "ce7b2f6c-ddc1-42bc-89d2-550cda4c54b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 75 candidates, totalling 75 fits\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=71, n_estimators=120, subsample=1.0;, score=-0.009 total time=  25.6s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=21, n_estimators=120, subsample=0.8;, score=-0.010 total time=  18.0s\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=81, n_estimators=80, subsample=0.4;, score=-0.019 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.030000000000000006, max_depth=51, n_estimators=170, subsample=0.6;, score=-0.010 total time=  33.1s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=41, n_estimators=130, subsample=0.5;, score=-2.053 total time=   5.9s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=11, n_estimators=80, subsample=0.9;, score=-1.112 total time=   4.3s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=1, n_estimators=130, subsample=0.5;, score=-0.015 total time=   2.5s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=21, n_estimators=170, subsample=0.1;, score=-0.009 total time=  16.9s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=91, n_estimators=140, subsample=0.7000000000000001;, score=-0.008 total time=  56.7s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=41, n_estimators=190, subsample=1.0;, score=-0.627 total time=  10.6s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=31, n_estimators=170, subsample=0.9;, score=-0.040 total time=  18.3s\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=61, n_estimators=100, subsample=0.4;, score=-0.010 total time=  17.1s\n",
      "[CV 1/1] END learning_rate=0.09000000000000001, max_depth=51, n_estimators=80, subsample=0.5;, score=-0.008 total time=  21.9s\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=71, n_estimators=130, subsample=1.0;, score=-0.008 total time=  30.5s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=11, n_estimators=90, subsample=0.7000000000000001;, score=-0.008 total time=  10.1s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=51, n_estimators=100, subsample=0.8;, score=-3.726 total time=   4.4s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=61, n_estimators=170, subsample=1.0;, score=-0.008 total time= 1.0min\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=51, n_estimators=160, subsample=1.0;, score=-0.008 total time=  33.4s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=91, n_estimators=140, subsample=0.4;, score=-0.008 total time=  42.6s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=1, n_estimators=50, subsample=0.4;, score=-0.498 total time=   1.1s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=31, n_estimators=110, subsample=1.0;, score=-0.008 total time=  27.4s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=1, n_estimators=110, subsample=0.6;, score=-0.024 total time=   2.2s\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=21, n_estimators=100, subsample=0.2;, score=-0.010 total time=   9.7s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=71, n_estimators=70, subsample=0.7000000000000001;, score=-0.010 total time=  13.3s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=71, n_estimators=140, subsample=1.0;, score=-0.008 total time=  47.3s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=21, n_estimators=160, subsample=0.5;, score=-0.008 total time=  36.5s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=1, n_estimators=180, subsample=0.4;, score=-0.775 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=41, n_estimators=170, subsample=0.4;, score=-0.042 total time=  16.9s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=21, n_estimators=190, subsample=0.30000000000000004;, score=-0.634 total time=   7.7s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=41, n_estimators=150, subsample=0.9;, score=-0.008 total time=  47.7s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=11, n_estimators=130, subsample=0.4;, score=-2.056 total time=   4.9s\n",
      "[CV 1/1] END learning_rate=0.06000000000000001, max_depth=1, n_estimators=50, subsample=0.4;, score=-0.082 total time=   1.1s\n",
      "[CV 1/1] END learning_rate=0.06000000000000001, max_depth=11, n_estimators=100, subsample=0.4;, score=-0.008 total time=  10.8s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=91, n_estimators=200, subsample=0.5;, score=-0.008 total time=  59.8s\n",
      "[CV 1/1] END learning_rate=0.09000000000000001, max_depth=61, n_estimators=90, subsample=0.6;, score=-0.008 total time=  29.2s\n",
      "[CV 1/1] END learning_rate=0.030000000000000006, max_depth=51, n_estimators=110, subsample=0.9;, score=-0.046 total time=  11.8s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=81, n_estimators=90, subsample=0.4;, score=-0.008 total time=  21.9s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=11, n_estimators=180, subsample=0.2;, score=-0.009 total time=  15.6s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=51, n_estimators=60, subsample=0.7000000000000001;, score=-0.015 total time=   9.6s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=11, n_estimators=140, subsample=0.4;, score=-0.009 total time=  14.5s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=91, n_estimators=190, subsample=0.8;, score=-0.008 total time= 1.2min\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=51, n_estimators=150, subsample=0.5;, score=-1.382 total time=   7.4s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=11, n_estimators=80, subsample=0.30000000000000004;, score=-1.121 total time=   2.9s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=21, n_estimators=130, subsample=0.5;, score=-0.008 total time=  27.2s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=31, n_estimators=120, subsample=0.9;, score=-0.008 total time=  31.0s\n",
      "[CV 1/1] END learning_rate=0.09000000000000001, max_depth=11, n_estimators=90, subsample=1.0;, score=-0.008 total time=   8.2s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=21, n_estimators=170, subsample=1.0;, score=-0.008 total time=  30.5s\n",
      "[CV 1/1] END learning_rate=0.06000000000000001, max_depth=11, n_estimators=110, subsample=1.0;, score=-0.008 total time=   9.9s\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=1, n_estimators=80, subsample=0.9;, score=-0.029 total time=   1.4s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=41, n_estimators=190, subsample=0.4;, score=-0.008 total time= 1.1min\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=41, n_estimators=60, subsample=0.2;, score=-0.229 total time=   2.6s\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=21, n_estimators=90, subsample=0.1;, score=-0.014 total time=   5.8s\n",
      "[CV 1/1] END learning_rate=0.09000000000000001, max_depth=71, n_estimators=180, subsample=0.9;, score=-0.008 total time=  59.7s\n",
      "[CV 1/1] END learning_rate=0.05000000000000001, max_depth=11, n_estimators=120, subsample=0.5;, score=-0.008 total time=  13.9s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=21, n_estimators=110, subsample=0.9;, score=-3.051 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=51, n_estimators=150, subsample=0.2;, score=-1.391 total time=   3.7s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=11, n_estimators=160, subsample=0.4;, score=-0.008 total time=  17.4s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=91, n_estimators=190, subsample=0.4;, score=-0.009 total time= 1.4min\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=91, n_estimators=140, subsample=0.2;, score=-0.009 total time=  25.0s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=1, n_estimators=190, subsample=0.9;, score=-0.636 total time=   3.1s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=11, n_estimators=70, subsample=0.2;, score=-0.110 total time=   3.4s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=51, n_estimators=120, subsample=0.7000000000000001;, score=-0.008 total time=  38.1s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=61, n_estimators=200, subsample=0.2;, score=-0.010 total time=  45.3s\n",
      "[CV 1/1] END learning_rate=0.07, max_depth=11, n_estimators=110, subsample=0.8;, score=-0.008 total time=  12.0s\n",
      "[CV 1/1] END learning_rate=0.08, max_depth=11, n_estimators=60, subsample=1.0;, score=-0.010 total time=   5.1s\n",
      "[CV 1/1] END learning_rate=0.04000000000000001, max_depth=51, n_estimators=70, subsample=0.2;, score=-0.109 total time=   3.5s\n",
      "[CV 1/1] END learning_rate=0.030000000000000006, max_depth=91, n_estimators=170, subsample=0.6;, score=-0.010 total time=  33.2s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=61, n_estimators=180, subsample=0.9;, score=-0.763 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=81, n_estimators=190, subsample=0.4;, score=-0.632 total time=   9.5s\n",
      "[CV 1/1] END learning_rate=0.06000000000000001, max_depth=81, n_estimators=80, subsample=0.30000000000000004;, score=-0.011 total time=  11.3s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=61, n_estimators=70, subsample=0.1;, score=-1.678 total time=   1.3s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=11, n_estimators=160, subsample=1.0;, score=-0.056 total time=  12.2s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=91, n_estimators=60, subsample=1.0;, score=-2.470 total time=   2.8s\n",
      "[CV 1/1] END learning_rate=0.06000000000000001, max_depth=81, n_estimators=50, subsample=0.6;, score=-0.072 total time=   5.0s\n",
      "[CV 1/1] END learning_rate=0.020000000000000004, max_depth=91, n_estimators=80, subsample=0.8;, score=-1.114 total time=   4.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=[(array([ 639, 2724, 5105, ..., 1653, 2607, 2732]),\n",
       "                        array([ 499, 3624, 2104, ..., 2584, 1363, 2744]))],\n",
       "                   estimator=XGBRegressor(objective='reg:squarederror'),\n",
       "                   n_iter=75,\n",
       "                   param_distributions={'learning_rate': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ]),\n",
       "                                        'max_depth': array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]),\n",
       "                                        'n_estimators': array([ 50,  60,  70,  80,  90, 100, 110, 120, 130, 140, 150, 160, 170,\n",
       "       180, 190, 200]),\n",
       "                                        'subsample': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "                   refit=False, scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = XGBRegressor(objective='reg:squarederror', random_state=0)\n",
    "\n",
    "search = RandomizedSearchCV(base_model, parameter_grid, \n",
    "                            cv=[(sampled_train_indices, sampled_valid_indices)], \n",
    "                            n_iter=(6 + 10 + 10 + 10 + 11 + 13 + 10 + 5),\n",
    "                            scoring=\"neg_mean_squared_error\", verbose=3, refit=False)\n",
    "\n",
    "search.fit(sampled_x_train, sampled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpQHTu8_W_jP",
    "outputId": "06c4ac3e-d15a-4527-e944-5086e55028dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08, 'max_depth': 21, 'n_estimators': 160, 'subsample': 0.5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCudLYzpW6UE",
    "outputId": "adac12c6-ef8d-4efd-d84a-dde2784e6d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007533777469334824\n"
     ]
    }
   ],
   "source": [
    "final_model = XGBRegressor(objective='reg:squarederror', random_state=0, **search.best_params_)\n",
    "final_model.fit(perth_train.drop('log10_price', axis=1), perth_train['log10_price'])\n",
    "\n",
    "y = perth_test['log10_price']\n",
    "y_pred = final_model.predict(perth_test.drop('log10_price', axis=1))\n",
    "\n",
    "print(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHPINck8XEU1",
    "outputId": "39ee7f9a-d99c-423a-9dd4-2fc6158687a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0075060996446797215\n"
     ]
    }
   ],
   "source": [
    "# Best Parameteres from Coordinate Descent\n",
    "base_parameters = {'learning_rate': 0.12999999999999998,\n",
    "                   'max_depth': 11,\n",
    "                   'n_estimators': 200,\n",
    "                   'subsample': 0.7999999999999999}\n",
    "\n",
    "final_model = XGBRegressor(objective='reg:squarederror', random_state=0, **base_parameters)\n",
    "final_model.fit(perth_train.drop('log10_price', axis=1), perth_train['log10_price'])\n",
    "\n",
    "y = perth_test['log10_price']\n",
    "y_pred = final_model.predict(perth_test.drop('log10_price', axis=1))\n",
    "\n",
    "print(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnfeyPLYkTFM"
   },
   "source": [
    "You'll see that random coordinate descent is just a bit better than randomized search, but it is basically quite similar. There are a couple of reasons why this might be\n",
    "\n",
    "1. The search for XGBoost wasn't ran till convergence (but the Random Forest was). You will know you have reached convergence when the previous iteration through the variables gives you the exact same values as the most recent iteration. This is why you should be running coordinate descent for way longer than I have done here.\n",
    "\n",
    "    Note that I ran coordinate descent a 2 more iterations after the notebook (so 4 in total) and it is almost at convergence with the parameters `{'learning_rate': 0.09, 'max_depth': 11, 'n_estimators': 170, 'subsample': 0.8}` and loss of `0.007313312056798277`. So defintely a significant improvement.\n",
    "\n",
    "2. It may just be that this dataset is very hard and the very small 0.00003 increase was actually very good.\n",
    "\n",
    "3. The more models you fit the more likely you are to converge to the correct answer. This is both true for both randomize search and coordinate descent. This means that if you sample a lot of parameters (i.e. if you try a lot of models) randomize search will give you similar results to coordinate descent.\n",
    "\n",
    "    Now since we are looping over the parameters twice, in this case, we end up sampling a lot of parameters. And with randomize search, if it can also sample a lot of parameters it can also do well as well.\n",
    "\n",
    "4. Coordinate descent works best when your loss function is convex (and smooth). If it is convex then convergence occurs in 1 loop over the parameters. But since we are using validation approach, rather than CV, it is highly unlikely that our loss function is convex. Making it harder for coordinate descent to work well.\n",
    "\n",
    "There are a couple of ways to make coordinate descent to work better. Since each time we are simply searching through one parameter, we can perform early stopping on this parameter. As an example, lets say that the grid for one of our parameters was\n",
    "\n",
    "```\n",
    "[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]\n",
    "```\n",
    "\n",
    "When we tried to optimize this parameter we found that the resulting validation error was\n",
    "\n",
    "```\n",
    "feature=1;, score=-10\n",
    "feature=2;, score=-9\n",
    "feature=3;, score=-8\n",
    "feature=4;, score=-10\n",
    "feature=5;, score=-11\n",
    "feature=6;, score=-12\n",
    "```\n",
    "\n",
    "There is no reason to continue and try the features `7, 8, 9, 10` because we know that these are simply going to give us larger values. So we can just stop here, meaning that rather than trying 10 parameters we only need to try 6 parameters. But I don't write the code for this because it takes too long, but you can try to do it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Random Search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
